{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import (KFold, LeaveOneOut, LeavePOut, \n",
    "                                     ShuffleSplit, StratifiedKFold, cross_val_score)\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring for `cross_val_score(model, X, y, cv=cv, scoring=scoring)`\n",
    "\n",
    "### Accuracy\n",
    "- **Definition**: Accuracy is the proportion of correctly classified samples.\n",
    "- **Use Case**: Default scoring for classification tasks.\n",
    "- **Example**: `scoring='accuracy'`\n",
    "\n",
    "---\n",
    "\n",
    "### Precision\n",
    "- **Definition**: Precision is the ratio of true positives to the sum of true positives and false positives. It answers, \"Of all the positive predictions, how many were actually correct?\"\n",
    "- **Example**: `scoring='precision'`\n",
    "  \n",
    "**Multiclass options**:\n",
    "- **`precision_macro`**: Calculates precision for each class and averages them, giving equal weight to all classes.\n",
    "- **`precision_micro`**: Aggregates the contributions of all classes (that is computes TP, TN, FP, FN across all classes and sums them up) to compute overall precision.\n",
    "- **`precision_weighted`**: Calculates precision for each class and averages them, weighted by the number of samples in each class.\n",
    "\n",
    "---\n",
    "\n",
    "### Recall\n",
    "- **Definition**: Recall (also known as sensitivity) is the ratio of true positives to the sum of true positives and false negatives. It answers, \"Of all the actual positives, how many did we correctly predict?\"\n",
    "- **Example**: `scoring='recall'`\n",
    "\n",
    "**Multiclass options**:\n",
    "- **`recall_macro`**: Averages recall over all classes, treating them equally.\n",
    "- **`recall_micro`**: Aggregates the contributions of all classes to compute overall recall.\n",
    "- **`recall_weighted`**: Averages recall weighted by the number of true instances in each class.\n",
    "\n",
    "---\n",
    "\n",
    "### F1 Score\n",
    "- **Definition**: The F1 score is the harmonic mean of precision and recall. It balances the two metrics, making it useful when there is an uneven class distribution.\n",
    "- **Example**: `scoring='f1'`\n",
    "\n",
    "**Multiclass options**:\n",
    "- **`f1_macro`**: Averages the F1 score across all classes equally.\n",
    "- **`f1_micro`**: Aggregates the contributions of all classes to compute an overall F1 score.\n",
    "- **`f1_weighted`**: Averages F1 scores, weighted by the number of instances in each class.\n",
    "\n",
    "---\n",
    "\n",
    "### ROC AUC\n",
    "- **Definition**: The area under the ROC curve (ROC AUC) measures the ability of the classifier to distinguish between classes. It's commonly used for binary classification.\n",
    "- **Example**: `scoring='roc_auc'`\n",
    "\n",
    "---\n",
    "\n",
    "### Average Precision\n",
    "- **Definition**: Average precision summarizes a precision-recall curve as the weighted mean of precision achieved at each threshold. It can be thought of as the area under the Precision-Recall curve.  It's particularly useful for imbalanced binary classification tasks.\n",
    "- **Example**: `scoring='average_precision'`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to evaluate KNN with cross-validation\n",
    "def evaluate_knn_cv(cross_validator, hyperparam_values, scoring, X, y):\n",
    "    for k in hyperparam_values:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        scores = cross_val_score(knn, X, y, cv=cross_validator, scoring=scoring)\n",
    "        print(f'K: {k}, Mean Accuracy: {scores.mean():.4f}, Std: {scores.std():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K values of the KNN  model to test\n",
    "hyperparam_values = [i for i in range(1,16)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold Cross Validation:\n",
      "K: 1, Mean Accuracy: 0.9600, Std: 0.0327\n",
      "K: 2, Mean Accuracy: 0.9600, Std: 0.0327\n",
      "K: 3, Mean Accuracy: 0.9667, Std: 0.0211\n",
      "K: 4, Mean Accuracy: 0.9733, Std: 0.0249\n",
      "K: 5, Mean Accuracy: 0.9733, Std: 0.0249\n",
      "K: 6, Mean Accuracy: 0.9733, Std: 0.0133\n",
      "K: 7, Mean Accuracy: 0.9733, Std: 0.0133\n",
      "K: 8, Mean Accuracy: 0.9733, Std: 0.0133\n",
      "K: 9, Mean Accuracy: 0.9667, Std: 0.0211\n",
      "K: 10, Mean Accuracy: 0.9733, Std: 0.0133\n",
      "K: 11, Mean Accuracy: 0.9733, Std: 0.0133\n",
      "K: 12, Mean Accuracy: 0.9733, Std: 0.0133\n",
      "K: 13, Mean Accuracy: 0.9800, Std: 0.0163\n",
      "K: 14, Mean Accuracy: 0.9800, Std: 0.0163\n",
      "K: 15, Mean Accuracy: 0.9733, Std: 0.0249\n"
     ]
    }
   ],
   "source": [
    "# 1. K-Fold Cross Validation\n",
    "print(\"K-Fold Cross Validation:\")\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "evaluate_knn_cv(kf, hyperparam_values, scoring='accuracy', X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leave One Out Cross Validation:\n",
      "K: 1, Mean Accuracy: 0.9600, Std: 0.1960\n",
      "K: 2, Mean Accuracy: 0.9467, Std: 0.2247\n",
      "K: 3, Mean Accuracy: 0.9600, Std: 0.1960\n",
      "K: 4, Mean Accuracy: 0.9600, Std: 0.1960\n",
      "K: 5, Mean Accuracy: 0.9667, Std: 0.1795\n",
      "K: 6, Mean Accuracy: 0.9600, Std: 0.1960\n",
      "K: 7, Mean Accuracy: 0.9667, Std: 0.1795\n",
      "K: 8, Mean Accuracy: 0.9667, Std: 0.1795\n",
      "K: 9, Mean Accuracy: 0.9667, Std: 0.1795\n",
      "K: 10, Mean Accuracy: 0.9733, Std: 0.1611\n",
      "K: 11, Mean Accuracy: 0.9733, Std: 0.1611\n",
      "K: 12, Mean Accuracy: 0.9600, Std: 0.1960\n",
      "K: 13, Mean Accuracy: 0.9667, Std: 0.1795\n",
      "K: 14, Mean Accuracy: 0.9733, Std: 0.1611\n",
      "K: 15, Mean Accuracy: 0.9733, Std: 0.1611\n"
     ]
    }
   ],
   "source": [
    "# 2. Leave One Out Cross Validation\n",
    "print(\"Leave One Out Cross Validation:\")\n",
    "loo = LeaveOneOut()\n",
    "evaluate_knn_cv(loo, hyperparam_values, scoring='accuracy', X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leave P Out Cross Validation (P = 2):\n",
      "K: 1, Mean Accuracy: 0.9599, Std: 0.1382\n",
      "K: 2, Mean Accuracy: 0.9467, Std: 0.1581\n",
      "K: 3, Mean Accuracy: 0.9600, Std: 0.1378\n",
      "K: 4, Mean Accuracy: 0.9601, Std: 0.1376\n",
      "K: 5, Mean Accuracy: 0.9665, Std: 0.1264\n",
      "K: 6, Mean Accuracy: 0.9601, Std: 0.1372\n",
      "K: 7, Mean Accuracy: 0.9667, Std: 0.1265\n",
      "K: 8, Mean Accuracy: 0.9667, Std: 0.1265\n",
      "K: 9, Mean Accuracy: 0.9666, Std: 0.1266\n",
      "K: 10, Mean Accuracy: 0.9711, Std: 0.1185\n",
      "K: 11, Mean Accuracy: 0.9728, Std: 0.1148\n",
      "K: 12, Mean Accuracy: 0.9603, Std: 0.1375\n",
      "K: 13, Mean Accuracy: 0.9670, Std: 0.1258\n",
      "K: 14, Mean Accuracy: 0.9733, Std: 0.1133\n",
      "K: 15, Mean Accuracy: 0.9730, Std: 0.1144\n"
     ]
    }
   ],
   "source": [
    "# 3. Leave P Out Cross Validation (P = 2)\n",
    "print(\"Leave P Out Cross Validation (P = 2):\")\n",
    "lpo = LeavePOut(p=2)\n",
    "evaluate_knn_cv(lpo, hyperparam_values, scoring='accuracy', X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffle & Split Cross Validation:\n",
      "K: 1, Mean Accuracy: 0.9733, Std: 0.0249\n",
      "K: 2, Mean Accuracy: 0.9667, Std: 0.0365\n",
      "K: 3, Mean Accuracy: 0.9733, Std: 0.0249\n",
      "K: 4, Mean Accuracy: 0.9667, Std: 0.0211\n",
      "K: 5, Mean Accuracy: 0.9733, Std: 0.0249\n",
      "K: 6, Mean Accuracy: 0.9733, Std: 0.0249\n",
      "K: 7, Mean Accuracy: 0.9667, Std: 0.0211\n",
      "K: 8, Mean Accuracy: 0.9800, Std: 0.0267\n",
      "K: 9, Mean Accuracy: 0.9600, Std: 0.0249\n",
      "K: 10, Mean Accuracy: 0.9800, Std: 0.0267\n",
      "K: 11, Mean Accuracy: 0.9600, Std: 0.0249\n",
      "K: 12, Mean Accuracy: 0.9733, Std: 0.0249\n",
      "K: 13, Mean Accuracy: 0.9667, Std: 0.0298\n",
      "K: 14, Mean Accuracy: 0.9600, Std: 0.0389\n",
      "K: 15, Mean Accuracy: 0.9600, Std: 0.0249\n"
     ]
    }
   ],
   "source": [
    "# 4. Shuffle & Split Cross Validation\n",
    "print(\"Shuffle & Split Cross Validation:\")\n",
    "ss = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "evaluate_knn_cv(ss, hyperparam_values, scoring='accuracy', X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified K-Fold Cross Validation:\n",
      "K: 1, Mean Accuracy: 0.9533, Std: 0.0499\n",
      "K: 2, Mean Accuracy: 0.9467, Std: 0.0452\n",
      "K: 3, Mean Accuracy: 0.9533, Std: 0.0499\n",
      "K: 4, Mean Accuracy: 0.9667, Std: 0.0298\n",
      "K: 5, Mean Accuracy: 0.9667, Std: 0.0298\n",
      "K: 6, Mean Accuracy: 0.9600, Std: 0.0389\n",
      "K: 7, Mean Accuracy: 0.9600, Std: 0.0389\n",
      "K: 8, Mean Accuracy: 0.9533, Std: 0.0340\n",
      "K: 9, Mean Accuracy: 0.9600, Std: 0.0249\n",
      "K: 10, Mean Accuracy: 0.9600, Std: 0.0249\n",
      "K: 11, Mean Accuracy: 0.9733, Std: 0.0249\n",
      "K: 12, Mean Accuracy: 0.9667, Std: 0.0298\n",
      "K: 13, Mean Accuracy: 0.9733, Std: 0.0249\n",
      "K: 14, Mean Accuracy: 0.9733, Std: 0.0249\n",
      "K: 15, Mean Accuracy: 0.9800, Std: 0.0163\n"
     ]
    }
   ],
   "source": [
    "# 5. Stratified K-Fold Cross Validation\n",
    "print(\"Stratified K-Fold Cross Validation:\")\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "evaluate_knn_cv(skf, hyperparam_values, scoring='accuracy', X=X, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'metric': 'euclidean', 'n_neighbors': 13}\n",
      "Best cross-validation score: 0.9800000000000001\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_neighbors': hyperparam_values,\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# Define the cross-validation strategy\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Output the best parameters\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def evaluate_knn_cv(cross_validator, hyperparam_values, scoring, X, y):\n",
    "    for k in hyperparam_values:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        cv_results = cross_validate(knn, X, y, cv=cross_validator, scoring=scoring, return_train_score=False)\n",
    "\n",
    "        # Extract the test scores\n",
    "        scores = {}\n",
    "        for score_type in scoring:\n",
    "            scores[score_type] = cv_results[f'test_{score_type}']\n",
    "            print(f'K: {k}, Mean {score_type}: {scores[score_type].mean():.4f}, Std {scores[score_type].std():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K values of the KNN  model to test\n",
    "hyperparam_values = [i for i in range(1,16,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold Cross Validation:\n",
      "K: 1, Mean recall_macro: 0.9594, Std 0.0310\n",
      "K: 1, Mean precision_macro: 0.9633, Std 0.0287\n",
      "K: 3, Mean recall_macro: 0.9649, Std 0.0221\n",
      "K: 3, Mean precision_macro: 0.9715, Std 0.0158\n",
      "K: 5, Mean recall_macro: 0.9744, Std 0.0247\n",
      "K: 5, Mean precision_macro: 0.9775, Std 0.0194\n",
      "K: 7, Mean recall_macro: 0.9720, Std 0.0147\n",
      "K: 7, Mean precision_macro: 0.9777, Std 0.0112\n",
      "K: 9, Mean recall_macro: 0.9633, Std 0.0222\n",
      "K: 9, Mean precision_macro: 0.9728, Std 0.0153\n",
      "K: 11, Mean recall_macro: 0.9699, Std 0.0165\n",
      "K: 11, Mean precision_macro: 0.9772, Std 0.0115\n",
      "K: 13, Mean recall_macro: 0.9794, Std 0.0174\n",
      "K: 13, Mean precision_macro: 0.9833, Std 0.0138\n",
      "K: 15, Mean recall_macro: 0.9728, Std 0.0276\n",
      "K: 15, Mean precision_macro: 0.9743, Std 0.0274\n"
     ]
    }
   ],
   "source": [
    "# 1. K-Fold Cross Validation\n",
    "print(\"K-Fold Cross Validation:\")\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "evaluate_knn_cv(kf, hyperparam_values, scoring=['recall_macro', 'precision_macro'], X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leave One Out Cross Validation:\n",
      "K: 1, Mean accuracy: 0.9600, Std 0.1960\n",
      "K: 1, Mean f1_micro: 0.9600, Std 0.1960\n",
      "K: 3, Mean accuracy: 0.9600, Std 0.1960\n",
      "K: 3, Mean f1_micro: 0.9600, Std 0.1960\n",
      "K: 5, Mean accuracy: 0.9667, Std 0.1795\n",
      "K: 5, Mean f1_micro: 0.9667, Std 0.1795\n",
      "K: 7, Mean accuracy: 0.9667, Std 0.1795\n",
      "K: 7, Mean f1_micro: 0.9667, Std 0.1795\n",
      "K: 9, Mean accuracy: 0.9667, Std 0.1795\n",
      "K: 9, Mean f1_micro: 0.9667, Std 0.1795\n",
      "K: 11, Mean accuracy: 0.9733, Std 0.1611\n",
      "K: 11, Mean f1_micro: 0.9733, Std 0.1611\n",
      "K: 13, Mean accuracy: 0.9667, Std 0.1795\n",
      "K: 13, Mean f1_micro: 0.9667, Std 0.1795\n",
      "K: 15, Mean accuracy: 0.9733, Std 0.1611\n",
      "K: 15, Mean f1_micro: 0.9733, Std 0.1611\n"
     ]
    }
   ],
   "source": [
    "# 2. Leave One Out Cross Validation\n",
    "print(\"Leave One Out Cross Validation:\")\n",
    "loo = LeaveOneOut()\n",
    "evaluate_knn_cv(loo, hyperparam_values, scoring=['accuracy', 'f1_micro'], X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leave P Out Cross Validation (P = 2):\n",
      "K: 1, Mean accuracy: 0.9599, Std 0.1382\n",
      "K: 1, Mean f1_micro: 0.9599, Std 0.1382\n",
      "K: 3, Mean accuracy: 0.9600, Std 0.1378\n",
      "K: 3, Mean f1_micro: 0.9600, Std 0.1378\n",
      "K: 5, Mean accuracy: 0.9665, Std 0.1264\n",
      "K: 5, Mean f1_micro: 0.9665, Std 0.1264\n",
      "K: 7, Mean accuracy: 0.9667, Std 0.1265\n",
      "K: 7, Mean f1_micro: 0.9667, Std 0.1265\n",
      "K: 9, Mean accuracy: 0.9666, Std 0.1266\n",
      "K: 9, Mean f1_micro: 0.9666, Std 0.1266\n",
      "K: 11, Mean accuracy: 0.9728, Std 0.1148\n",
      "K: 11, Mean f1_micro: 0.9728, Std 0.1148\n",
      "K: 13, Mean accuracy: 0.9670, Std 0.1258\n",
      "K: 13, Mean f1_micro: 0.9670, Std 0.1258\n",
      "K: 15, Mean accuracy: 0.9730, Std 0.1144\n",
      "K: 15, Mean f1_micro: 0.9730, Std 0.1144\n"
     ]
    }
   ],
   "source": [
    "# 3. Leave P Out Cross Validation (P = 2)\n",
    "print(\"Leave P Out Cross Validation (P = 2):\")\n",
    "lpo = LeavePOut(p=2)\n",
    "evaluate_knn_cv(lpo, hyperparam_values, scoring=['accuracy', 'f1_micro'], X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffle & Split Cross Validation:\n",
      "K: 1, Mean accuracy: 0.9733, Std 0.0249\n",
      "K: 1, Mean f1_micro: 0.9733, Std 0.0249\n",
      "K: 3, Mean accuracy: 0.9733, Std 0.0249\n",
      "K: 3, Mean f1_micro: 0.9733, Std 0.0249\n",
      "K: 5, Mean accuracy: 0.9733, Std 0.0249\n",
      "K: 5, Mean f1_micro: 0.9733, Std 0.0249\n",
      "K: 7, Mean accuracy: 0.9667, Std 0.0211\n",
      "K: 7, Mean f1_micro: 0.9667, Std 0.0211\n",
      "K: 9, Mean accuracy: 0.9600, Std 0.0249\n",
      "K: 9, Mean f1_micro: 0.9600, Std 0.0249\n",
      "K: 11, Mean accuracy: 0.9600, Std 0.0249\n",
      "K: 11, Mean f1_micro: 0.9600, Std 0.0249\n",
      "K: 13, Mean accuracy: 0.9667, Std 0.0298\n",
      "K: 13, Mean f1_micro: 0.9667, Std 0.0298\n",
      "K: 15, Mean accuracy: 0.9600, Std 0.0249\n",
      "K: 15, Mean f1_micro: 0.9600, Std 0.0249\n"
     ]
    }
   ],
   "source": [
    "# 4. Shuffle & Split Cross Validation\n",
    "print(\"Shuffle & Split Cross Validation:\")\n",
    "ss = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "evaluate_knn_cv(ss, hyperparam_values, scoring=['accuracy', 'f1_micro'], X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified K-Fold Cross Validation:\n",
      "K: 1, Mean accuracy: 0.9533, Std 0.0499\n",
      "K: 1, Mean f1_micro: 0.9533, Std 0.0499\n",
      "K: 3, Mean accuracy: 0.9533, Std 0.0499\n",
      "K: 3, Mean f1_micro: 0.9533, Std 0.0499\n",
      "K: 5, Mean accuracy: 0.9667, Std 0.0298\n",
      "K: 5, Mean f1_micro: 0.9667, Std 0.0298\n",
      "K: 7, Mean accuracy: 0.9600, Std 0.0389\n",
      "K: 7, Mean f1_micro: 0.9600, Std 0.0389\n",
      "K: 9, Mean accuracy: 0.9600, Std 0.0249\n",
      "K: 9, Mean f1_micro: 0.9600, Std 0.0249\n",
      "K: 11, Mean accuracy: 0.9733, Std 0.0249\n",
      "K: 11, Mean f1_micro: 0.9733, Std 0.0249\n",
      "K: 13, Mean accuracy: 0.9733, Std 0.0249\n",
      "K: 13, Mean f1_micro: 0.9733, Std 0.0249\n",
      "K: 15, Mean accuracy: 0.9800, Std 0.0163\n",
      "K: 15, Mean f1_micro: 0.9800, Std 0.0163\n"
     ]
    }
   ],
   "source": [
    "# 5. Stratified K-Fold Cross Validation\n",
    "print(\"Stratified K-Fold Cross Validation:\")\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "evaluate_knn_cv(skf, hyperparam_values, scoring=['accuracy', 'f1_micro'], X=X, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'metric': 'euclidean', 'n_neighbors': 13}\n",
      "Best cross-validation score (f1_micro): 0.9832556332556333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_neighbors': hyperparam_values,  # List of neighbor values to test\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# Define the cross-validation strategy\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the model\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Perform grid search with cross-validation optimizing both sensitivity and specificity\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=cv, scoring=['recall_macro', 'precision_macro'], refit='precision_macro')\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score (f1_micro):\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example on Grid Search and Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3029</th>\n",
       "      <td>white</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.29</td>\n",
       "      <td>14.8</td>\n",
       "      <td>0.024</td>\n",
       "      <td>22.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0.99518</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.48</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5406</th>\n",
       "      <td>red</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.31</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.090</td>\n",
       "      <td>26.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.99940</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.63</td>\n",
       "      <td>10.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>white</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.24</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.045</td>\n",
       "      <td>36.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.99220</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.64</td>\n",
       "      <td>11.3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>white</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.044</td>\n",
       "      <td>25.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.99310</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.38</td>\n",
       "      <td>10.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4414</th>\n",
       "      <td>white</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0.041</td>\n",
       "      <td>26.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.99335</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.52</td>\n",
       "      <td>11.5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       type  fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "3029  white            7.1              0.47         0.29            14.8   \n",
       "5406    red           10.0              0.59         0.31             2.2   \n",
       "2207  white            6.6              0.23         0.24             3.9   \n",
       "63    white            6.6              0.38         0.15             4.6   \n",
       "4414  white            7.1              0.27         0.27            10.4   \n",
       "\n",
       "      chlorides  free sulfur dioxide  total sulfur dioxide  density    pH  \\\n",
       "3029      0.024                 22.0                 142.0  0.99518  3.12   \n",
       "5406      0.090                 26.0                  62.0  0.99940  3.18   \n",
       "2207      0.045                 36.0                 138.0  0.99220  3.15   \n",
       "63        0.044                 25.0                  78.0  0.99310  3.11   \n",
       "4414      0.041                 26.0                 114.0  0.99335  3.04   \n",
       "\n",
       "      sulphates  alcohol  quality  \n",
       "3029       0.48     12.0        8  \n",
       "5406       0.63     10.2        6  \n",
       "2207       0.64     11.3        7  \n",
       "63         0.38     10.2        6  \n",
       "4414       0.52     11.5        7  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('./data/winequality.csv')\n",
    "df.sample(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing \n",
    "df['target'] = np.where(df['quality']>5, 1, 0)\n",
    "df['type'] = np.where(df['type']=='red', 1, 0)\n",
    "df2 = df.drop(['quality'],axis=1)\n",
    "X = df2.drop(['target'],axis=1)\n",
    "y = df2['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initializing random forest\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search cv\n",
    "grid_space={'max_depth':[3,5,10,None],\n",
    "              'n_estimators':[10,100,200],\n",
    "              'max_features':[1,3,5,7],\n",
    "              'min_samples_leaf':[1,2,3],\n",
    "              'min_samples_split':[1,2,3]\n",
    "           }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Darling\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "432 fits failed out of a total of 1296.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "432 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Darling\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Darling\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Darling\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Darling\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Darling\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\ma\\core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n",
      "c:\\Users\\Darling\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.66123177 0.65769414 0.65969582\n",
      " 0.64444949 0.65153456 0.6578474         nan        nan        nan\n",
      " 0.65276465 0.65984872 0.66862492 0.64876334 0.65276671 0.65784725\n",
      "        nan        nan        nan 0.65430728 0.66908596 0.65754004\n",
      " 0.67046986 0.65138138 0.66138908        nan        nan        nan\n",
      " 0.70171124 0.70079015 0.70325323 0.69139902 0.70248298 0.70079044\n",
      "        nan        nan        nan 0.69801993 0.70494684 0.70048258\n",
      " 0.71110258 0.69801765 0.70186783        nan        nan        nan\n",
      " 0.68154323 0.71079465 0.70340712 0.66107397 0.7034072  0.70125148\n",
      "        nan        nan        nan 0.70755798 0.71756483 0.71525579\n",
      " 0.70355519 0.71602518 0.71725697        nan        nan        nan\n",
      " 0.69432478 0.714332   0.71540968 0.70925543 0.71479375 0.71633333\n",
      "        nan        nan        nan 0.71864187 0.71109967 0.71679557\n",
      " 0.70801753 0.71879562 0.71402407        nan        nan        nan\n",
      " 0.71602469 0.71125257 0.71202217 0.70586373 0.71094442 0.71248414\n",
      "        nan        nan        nan 0.71217529 0.71294589 0.71263839\n",
      " 0.71094428 0.71571647 0.71571711        nan        nan        nan\n",
      " 0.72110474 0.71910462 0.71371614 0.71648629 0.71248464 0.71140646\n",
      "        nan        nan        nan 0.66322336 0.68493564 0.67846849\n",
      " 0.66199648 0.67923788 0.67677559        nan        nan        nan\n",
      " 0.68955436 0.6709233  0.68216342 0.6763122  0.67939341 0.67939362\n",
      "        nan        nan        nan 0.67354183 0.67846763 0.68416553\n",
      " 0.66814945 0.68755126 0.6786216         nan        nan        nan\n",
      " 0.70155351 0.71802224 0.69877959 0.68476909 0.6977019  0.69693116\n",
      "        nan        nan        nan 0.68707799 0.70970922 0.69754879\n",
      " 0.71556101 0.69308254 0.70663036        nan        nan        nan\n",
      " 0.69724563 0.70385963 0.70108827 0.68554304 0.70401445 0.70616854\n",
      "        nan        nan        nan 0.70678631 0.71109455 0.70662908\n",
      " 0.69262164 0.7070936  0.7127878         nan        nan        nan\n",
      " 0.71786821 0.69739305 0.70539821 0.70586224 0.70324235 0.71109434\n",
      "        nan        nan        nan 0.70447421 0.6993936  0.70077871\n",
      " 0.70832425 0.70478236 0.7043206         nan        nan        nan\n",
      " 0.72464258 0.70478193 0.71078534 0.71663912 0.70586061 0.70601358\n",
      "        nan        nan        nan 0.69631317 0.70678361 0.70662887\n",
      " 0.69939608 0.71078662 0.70863083        nan        nan        nan\n",
      " 0.69985513 0.70693758 0.71109362 0.70324527 0.70662887 0.70924676\n",
      "        nan        nan        nan 0.67815281 0.69200244 0.69816074\n",
      " 0.67322495 0.69908432 0.70339547        nan        nan        nan\n",
      " 0.698475   0.69815939 0.69307963 0.68923677 0.70601301 0.69831428\n",
      "        nan        nan        nan 0.69555003 0.70231814 0.69692952\n",
      " 0.70801796 0.69923714 0.69708249        nan        nan        nan\n",
      " 0.69139128 0.70170001 0.69754467 0.68815489 0.69400299 0.70185312\n",
      "        nan        nan        nan 0.68399927 0.70755016 0.69631132\n",
      " 0.70770584 0.71124446 0.70416195        nan        nan        nan\n",
      " 0.67984159 0.69477217 0.69846625 0.68214906 0.699237   0.70462505\n",
      "        nan        nan        nan 0.68322682 0.70046886 0.70478008\n",
      " 0.68738564 0.70447165 0.69277084        nan        nan        nan\n",
      " 0.69693229 0.69692696 0.70416351 0.69908616 0.69569681 0.69769814\n",
      "        nan        nan        nan 0.68538445 0.70185532 0.69831321\n",
      " 0.69261979 0.69939196 0.69939075        nan        nan        nan\n",
      " 0.70416501 0.6950806  0.7012379  0.69878108 0.70585876 0.70416408\n",
      "        nan        nan        nan 0.70432103 0.7072438  0.69769743\n",
      " 0.69262143 0.70231672 0.69708334        nan        nan        nan\n",
      " 0.68661453 0.70616512 0.70077693 0.70940421 0.6992375  0.70154654\n",
      "        nan        nan        nan 0.6615247  0.6960031  0.69523165\n",
      " 0.679536   0.70631845 0.698005          nan        nan        nan\n",
      " 0.681693   0.71139935 0.70400898 0.67584419 0.70093132 0.69646614\n",
      "        nan        nan        nan 0.67307091 0.69215456 0.70631859\n",
      " 0.69000574 0.69677485 0.69384895        nan        nan        nan\n",
      " 0.67476346 0.69477139 0.69045988 0.68138557 0.69985257 0.69138566\n",
      "        nan        nan        nan 0.6860018  0.69277028 0.69861958\n",
      " 0.69785466 0.7069336  0.69492493        nan        nan        nan\n",
      " 0.69153941 0.7020058  0.69800443 0.67922743 0.69631061 0.70123662\n",
      "        nan        nan        nan 0.66875976 0.6986215  0.70200907\n",
      " 0.66644887 0.70339312 0.69892793        nan        nan        nan\n",
      " 0.6763014  0.69692611 0.69415453 0.67460764 0.69815982 0.69861972\n",
      "        nan        nan        nan 0.68630916 0.70308462 0.70262323\n",
      " 0.68384552 0.69630975 0.69892822        nan        nan        nan\n",
      " 0.66213992 0.69077122 0.70200758 0.67061039 0.69338592 0.69461771\n",
      "        nan        nan        nan 0.70139627 0.69862008 0.69923665\n",
      " 0.69539457 0.70293172 0.69692867        nan        nan        nan\n",
      " 0.69400889 0.69631025 0.6916938  0.68199695 0.69723596 0.69554249]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(rf,param_grid=grid_space,cv=3,scoring='accuracy')\n",
    "model_grid = grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best grid search hyperparameters are: {'max_depth': 5, 'max_features': 7, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "Best grid search score is: 0.7246425796674337\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# grid search results\n",
    "print('Best grid search hyperparameters are: '+str(model_grid.best_params_))\n",
    "print('Best grid search score is: '+str(model_grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best random search hyperparameters are: {'criterion': 'gini', 'max_depth': 80, 'max_features': 6, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 60}\n",
      "Best random search score is: 0.7137081084462301\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# random search cv\n",
    "rs_space={'max_depth':list(np.arange(10, 100, step=10)) + [None],\n",
    "              'n_estimators':np.arange(10, 500, step=50),\n",
    "              'max_features':randint(1,7),\n",
    "              'criterion':['gini','entropy'],\n",
    "              'min_samples_leaf':randint(1,4),\n",
    "              'min_samples_split':np.arange(2, 10, step=2)\n",
    "          }\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf_random = RandomizedSearchCV(rf, rs_space, n_iter=500, scoring='accuracy', n_jobs=-1, cv=3)\n",
    "model_random = rf_random.fit(X,y)\n",
    "\n",
    "# random random search results\n",
    "print('Best random search hyperparameters are: '+str(model_random.best_params_))\n",
    "print('Best random search score is: '+str(model_random.best_score_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
